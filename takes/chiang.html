<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <link rel="shortcut icon" type="image/x-icon" href="../img/favicon.ico">
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>chiang</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="main.css" />
</head>
<body>
<h2
id="a-response-to-certain-paragraphs-from-the-interview-sci-fi-writer-ted-chiang-the-machines-we-have-now-are-not-conscious">A
response to certain paragraphs from the interview “Sci-fi writer Ted
Chiang: ‘The machines we have now are not conscious’”</h2>
<p><a
href="https://www.ft.com/content/c1f6d948-3dde-405f-924c-09cc0dcf8c84"
class="uri">https://www.ft.com/content/c1f6d948-3dde-405f-924c-09cc0dcf8c84</a></p>
<p>response written 2023/06/03</p>
<p>“It’s genuinely amazing that these sorts of things can be extracted
from a statistical analysis of a large body of text,” he says. But, in
his view, that doesn’t make the tools intelligent. Applied statistics is
a far more precise descriptor, “but no one wants to use that term,
because it’s not as sexy”.”</p>
<p>See on mu meelest väär. Kui mudel on treenitud hästi teksti
ennustama, siis jääb mulle arusaamatuks, kuidas sellest saab midagi
selle kohta järeldada, et milline algoritm treenitud mudelis
implementeeritud on. Teksti võib ilmselt ennustada igasugu viisidel, mis
on vähem või rohkem intelligentsed. Näiteks on üks viis teksti
ennustamiseks mõelda nii, nagu inimene teksti ennustades mõtleks. Teine
viis teksti ennustamiseks oleks teha midagi, mis on natuke rohkem nagu
“applied statistics”, nt vaadata viimast kahte sõna ja väljastada
vastus, mis esines treeningandmetes pärast neid kahte sõna kõige rohkem.
Me teame, et täpselt teist varianti praegused mudelid ei tee, sest
sellega ei saaks kaugeltki neid asju teha, mida GPT-4 teeb. Ilmselt ei
mõtle GPT-4 teksti ennustamisest ka nii, nagu inimene teksti
ennustamisest mõtleks. Minu teada ei tea keegi seni selle kohta suht
midagi, kuidas GPT-4 teksti ennustab. Kõige keerulisem asi, millest
inimestel on õnnestunud seni aru saada, on minu teada siit artiklist: <a
href="https://arxiv.org/pdf/2211.00593.pdf"
class="uri">https://arxiv.org/pdf/2211.00593.pdf</a>. Täpsemalt
selgitatakse siin välja, mis algoritmi GPT-2 kasutab lausete nagu “When
Mary and John went to the store, John gave a bottle of milk to…” õige
sõnaga (antud näites “Mary”) lõpetamiseks, mis pole lähedalgi nt sellest
aru saamisele, et kuidas GPT-4 oskab ühtegi siin mainitud asja teha: <a
href="https://www.youtube.com/watch?v=qbIk7-JPB2c"
class="uri">https://www.youtube.com/watch?v=qbIk7-JPB2c</a></p>
<p>Statistikaga on GPT-4 puhul ka umbes ainult nii palju pistmist, et
statistika uurib asjade ennustamist ja GPT-4 ennustab tekstis järgmiseid
sõnu. Ja see pole isegi ka päris õige — õigem oleks öelda, et GPT-4
põhineb mudelil, mis on treenitud ennustama järgmiseid sõnu. Aga sellest
baasmudelist GPT-4 saamiseks on ilmselt seda pärast ka muid eesmärke
täitma treenitud</p>
<p>Üks viis nende mudelite oskustest mõelda on järgnev: vaadata, mida
mudelid 4 aastat tagasi teha oskasid (nt mida GPT-2 teha oskab);
vaadata, mida mudelid 2 aastat tagasi teha oskasid (nt GPT-3) ja
vaadata, mida mudelid praegu teha oskavad (nt GPT-4); ja siis mõelda, et
kui sarnase suurusega sammudes edasi liikuda, siis mida mudelid paari
aasta pärast teha võiksid osata. Ma oleksin üllatunud, kui 15 aasta
pärast ei oskaks AI teha kõiki asju, mida inimesed praegu teha
oskavad.</p>
<p>Teadvuse küsimus on intelligentsuse küsimusest vist erinev. Artiklis
esitatud argumendid jäävad mulle selle küsimuse osas suht arusaamatuks,
nt:</p>
<p>““The machines we have now, they’re not conscious,” he says. “When
one person teaches another person, that is an interaction between
consciousnesses.” Meanwhile, AI models are trained by toggling so-called
“weights” or the strength of connections between different variables in
the model, in order to get a desired output. “It would be a real mistake
to think that when you’re teaching a child, all you are doing is
adjusting the weights in a network.””</p>
<p>Ma ei saa aru, mis erinevustele see lõik viitab. Et kui üks inimene
teist õpetab, siis ta ajust läheb teadvus teise inimese ajju? Et kui
inimene õpib, siis ajus toimub mingi protsess, mis pole lihtsalt
füüsiliste parameetrite muutmine, mis on kuidagi teadvuse saamiseks
vajalik? Kui ta siin jutus millelegi mõistlikule viitab, siis ma ei saa
aru, millele täpsemalt, nii et ma ei oska sellele sisukalt vastata. Aga
üldiselt inimesed pole võlukunst</p>
</body>
</html>
