<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <link rel="shortcut icon" type="image/x-icon" href="../../img/favicon.ico">
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>8</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="main.css" />
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<h1
id="making-an-ai-which-is-broadly-smarter-than-humanity-would-be-most-significant"><a
href="https://www.lesswrong.com/posts/iemgJhjNLa5eyevWR/kh-s-shortform?commentId=nTfRyNgzGSLowN2Wn">8
making an AI which is broadly smarter than humanity would be most
significant</a></h1>
<ol type="1">
<li>The previous notes might leave the impression that I think the
future of thinking looks like business as usual. The point of this note
is to clarify some ways in which I very much do not think this.</li>
<li>Yes, I think it is unlikely that “the history/development of thought
will end”<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a>, but I very much don’t think that
the future just brings more of the usual.</li>
<li>First, what I’ve been saying is “in many ways, the future will be
like it has been before — that is, it brings completely crazy things
which cannot be remotely-well-anticipated, like arithmetic, the printing
press, probability, formal logic, computers, or maybe even like
primitive compositional language<a href="#fn2" class="footnote-ref"
id="fnref2" role="doc-noteref"><sup>2</sup></a>, very many times”, which
is hardly well-captured by “the future just brings more of the usual”
alone.</li>
<li>Second, these notes are written during a period with a high
probability per year of humanity making an artificial system more
intelligent/capable than us<a href="#fn3" class="footnote-ref"
id="fnref3" role="doc-noteref"><sup>3</sup></a>. That would very much
not be “business as usual” — I think it would plausibly be comparably
important to evolution or culture getting started, given the central
role that intelligence/capability has in the world and the fact that
gains in intelligence and understanding will likely be much faster (by
default) [once an artifact smarter than humans/humanity has been
created] than they have been historically in humanity/humans.
<ol type="1">
<li>One reason things will be crazy once such an artifact is created is
that it makes thinking much more open to being intelligently reshaped
than before (including just scaling a mind up). A great deal of somewhat
intelligent design of thinking has happened already (for example,
humanity is doing some of that (roughly) every time we create a new
useful word-concept), but making an artifact more intelligent than us
and distinct from us will almost certainly make much more powerful forms
of reshaping thought available — it would open up many aspects of
thought to much more potent kinds of improvement.</li>
<li>For a very weak lower bound on what happens by default, imagine just
being able to make very many “people” at least as smart as the smartest
people who have appeared so far, and running them <span
class="math inline">\(100\)</span> times faster, potentially making as
much scientific/mathematical/philosophical progress in a year as might
have taken a century without artificial intelligence. In particular, you
can have this much progress be made in the field of artificial
intelligence itself. Really, things will be much crazier than 100 years
of usual progress happening in 1 year.</li>
<li>Generally, intelligence is just very powerful! Like, the structures
in our world are almost entirely made by thought-like processes. When
you look around, almost all the objects you see had to be invented by
people or by evolution (or the two together) — if you look right, you
see “reified/implemented ideas” everywhere — and there is very very much
more significant stuff to invent.<a href="#fn4" class="footnote-ref"
id="fnref4" role="doc-noteref"><sup>4</sup></a> The world is only going
to become much more shaped/built by thinking than it is now (assuming
thinking sticks around). Your own mind is made using evolution’s
“thinking” and humanity’s thinking and in particular your own thinking
and your parents’/teachers’/friends’ thinking.</li>
</ol></li>
<li>Furthermore, by default, the intelligent system(s) we’d create would
be radically different from us — this contributes further to the
creation of such a system being a drastic event.</li>
<li>So, given that by default, an artifact more intelligent/capable than
us is created this century, by default, it is “the big thing” of our
time.</li>
</ol>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>I don’t mean anything that mysterious here — I largely
just mean what I’ve already said in previous notes, though this theme
and the broader them that history won’t end could be developed much
further (it will be developed a bit further in later notes).<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Instead of ”primitive compositional language”, I
originally wanted to say ”language” here, but since I don’t think
language is that much of a definite single thing — I think it is a
composite of many ”ideas”, and very open to new ”ideas” getting involved
— I went with ”primitive compositional language”, trying to give a
slightly less composite thing. But that is surely still not that
unitary.<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>or maybe multiple such systems, in parallel or in
succession<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>There are also some things made by/of other life (such
as a beaver dam and a forest ecosystem) and some things made by physics
(such as stars, planets, oceans, volcanoes, clouds). There’s often
(almost always?) some selection/optimization process going on even to
make these structures “of mere physics”.<a href="#fnref4"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
