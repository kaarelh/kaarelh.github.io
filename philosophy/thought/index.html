<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <link rel="shortcut icon" type="image/x-icon" href="../../img/favicon.ico">
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>index</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="main.css" />
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<h1 id="an-advent-of-thought"><a
href="https://www.lesswrong.com/posts/nkeYxjdrWBJvwbnTr">An Advent of
Thought</a></h1>
<ol type="1">
<li>I was intending to write and post one (hypo)thesis [relating to
thinking (with an eye toward alignment)] each day this Advent, starting
on 24/12/01 and finishing on 24/12/24.</li>
<li>Ok, so that didn’t happen, but whatever — an advent of thought can
happen whenever :). I’ll be posting the first 8 notes today (25/03/17).
(But much of the writing was done in 24/12/[01–24].)</li>
<li>Most of these notes deal with questions that would really deserve to
have very much more said about them — the brief treatments I give these
questions here won’t be doing them any justice. I hope to think and
write more about many of the topics here in the future.<a href="#fn1"
class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></li>
<li>I’ve tried to state strong claims. I do (inside view?) believe each
individual claim (at maybe typically <span class="math inline">\(p\geq
0.85\)</span><a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>), but I certainly feel uneasy about
many claims (feel free to imagine a version of the notes with even more
“probably”s and “plausibly”s if you’d prefer that style) — I feel like I
haven’t thought about many of the questions adequately, and I’m surely
missing many important considerations.<a href="#fn3"
class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> I’m
certainly worried I’m wrong about it all!<sup>[especially given that to
a significant extent, the claims stand together or fall
together]</sup>[if in a few years I don’t think I was wrong/confused
about major things here, I should seriously consider considering myself
to have <a
href="https://en.wikipedia.org/wiki/Paul_Erd%C5%91s#Personality">died</a>
:)]</li>
<li>Even if you happen to find my theses/arguments/analysis
wrong/lacking/confused, I’m hopeful you might find [the hypotheses]/[the
questions my notes are trying to make progress on] interesting.</li>
<li>If you reason me out of some claim in this list, I’d find that
valuable!<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a></li>
<li>While many notes can stand alone, there are some dependencies, so
I’d recommend reading the notes in the given order. The (hypo)theses
present a somewhat unified view, there are occasional overlaps in their
contents, and there are positive correlations between their truth
values. A table of contents:
<ol type="1">
<li>notes 1–8: on thought, (its) history (past and future), and
alignment, with an aim to make us relate more appropriately to
“understanding thinking” and “solving alignment”<a href="#fn5"
class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>
<ol type="1">
<li><a href="./1.html">thinking can only be infinitesimally
understood</a></li>
<li><a href="./2.html">infinitude spreads</a></li>
<li><a href="./3.html">math, thinking, and technology are
equi-infinite</a></li>
<li><a href="./4.html">general intelligence is not that
definite</a></li>
<li><a href="./5.html">confusion isn’t going away</a></li>
<li><a href="./6.html">thinking (ever better) will continue</a></li>
<li><a href="./7.html">alignment is infinite</a></li>
<li><a href="./8.html">making an AI which is broadly smarter than
humanity would be most significant</a></li>
</ol></li>
<li>notes 9–18: on values/valuing, their/its history (past and future),
and their/its relation to understanding, with an aim to help us think
better about our own values and the values present/dominant in the world
if we create an artifact distinct and separate from humanity which is
smarter than humanity (not published yet)</li>
<li>notes 19–24: on worthwhile futures just having humanity grow more
intelligent and skillful indefinitely (as opposed to ever creating an
artifact distinct and separate from us which outgrows us<a href="#fn6"
class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>),
with an aim to get us to set our minds tentatively to doing just that
(not published yet)</li>
</ol></li>
</ol>
<p>Acknowledgments. I have benefited from and made use of the following
people’s unpublished and/or published ideas on these topics: especially
Sam Eisenstat; second-most-importantly Tsvi Benson-Tilsen; also: Clem
von Stengel, Jake Mendel, Kirke Joamets, Jessica Taylor, Dmitry
Vaintrob, Simon Skade, Rio Popper, Lucius Bushnaq, <a
href="https://n.cohomology.group/">Mariven</a>, Hoagy Cunningham, Hugo
Eberhard, Peli Grietzer, Rudolf Laine, Samuel Buteau, Jeremy Gillen,
Kaur Aare Saar, Nate Soares, Eliezer Yudkowsky, Hasok Chang, Ian
Hacking, Ludwig Wittgenstein, <a
href="https://www.youtube.com/playlist?list=PLLQHcGVaP6vtDUDYgBLOFAMCu2DDsnN_Q">Martin
Heidegger and Hubert Dreyfus</a>, <a
href="https://www.youtube.com/playlist?list=PL4gvlOxpKKIgR4OyOt31isknkVH2Kweq2">Georg
Wilhelm Friedrich Hegel and Gregory B. Sadler</a>, various other
canonical philosophers, and surely various others I’m currently
forgetting.<a href="#fn7" class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a></p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>In particular, I might improve/rewrite/expand and
republish some of the present notes in the future.<a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>though I expect a bunch of them to eventually come to be
of type nonsense<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>You know how when people in the room are saying <span
class="math inline">\(X\)</span> and you think sorta-<span
class="math inline">\(X\)</span>-but-sorta-not-<span
class="math inline">\(X\)</span>, then you might find yourself arguing
for not-<span class="math inline">\(X\)</span> in this room (but if you
were trying to be helpful in a room of not-<span
class="math inline">\(X\)</span>-ers, you’d find yourself arguing for
<span class="math inline">\(X\)</span> in that room), and it’s easy to
end up exaggerating your view somewehat in the direction of not-<span
class="math inline">\(X\)</span> in this situation? These notes have an
early archeological layer in which I was doing more of that, but I
decided later that this was annoying/bad, so this early layer has now
largely been covered up in the present palimpsest. The title
(hypo)theses are a main exception — to keep them crisp, I’ve kept many
of them hyperbolic (but stated my actual position in the body of the
note).<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Still, it could happen that I don’t respond to a
response; in particular, it could happen that [I won’t find your attempt
to reason me out of some position compelling, but I also don’t provide
counterarguments], and it could happen that I learn something from your
comment but fail to thank you. So, you know, sorry/thanks ahead of time
:).<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>I use scare quotes throughout these notes to indicate
terms/concepts which I consider particularly
bad/confused/unreliable/suspect/uncomfortable/unfortunate/in-need-of-a-rework;
I do not mean to further indicate sneering. (I also use double quotation
marks in the more common way though — i.e., just to denote phrases.)<a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>or multiple artifacts distinct and separate from us
which outgrow us<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>I might go through the notes at some point later and add
more specific acknowledgments — there are currently a bunch of things
which are either fairly directly from someone or in response to someone
or developed together with someone. Many things in these notes are
really responses to past me(s), though I don’t take them to exactly have
taken a contrary (so wrong :)) position most of the time, but more [to
have lacked a clear view on] or [to have had only bad ways to think
about] matters.<a href="#fnref7" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
